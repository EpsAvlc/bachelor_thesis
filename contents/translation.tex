% !Mode:: "TeX:UTF-8"

\chapter{You Only Look Once:统一的实时目标检测方法}

\section{介绍}

人只需要瞄一眼图像就能立刻知道图像上的物体是什么，物体在哪儿。人类的视觉系统快速又精确，允许我们处理复杂的任务，例如几乎不需要太多思考地驾驶汽车。快速，准确的目标识别算法能够让电脑自动去驾驶汽车而不需要别的特定的传感器，给驾驶员提供实时的传感器信息，提供实现响应式的机器人系统的可能。

目前的检测系统是对分类器的改进。为了检测一个目标，这些系统训练出一个专门针对这个目标的分类器，并在图像中的不同位置、不同大小处去检验分类器的值。一些系统如deformable parts models（DPM）使用滑动窗口的方法来检测障碍物，其中的分类器在图像的每一个相等大小的子图像块上做分类任务。

更多最近的算法如R-CNN使用区域候选（region proposal）方法来在图像中快速产生可能的边界框，然后在这些候选的框内使用分类方法。在分类后，对这些边界框进行处理以使得边界框更准确，并去除面积重叠的边界框，对框中的物体重新评估其准确率与置信度。这些复杂的方法运算速度较慢，并且很难优化，因为每个分类器都需要分开来单独训练。

我们重新构架了目标检测任务，认为它只是一个单纯的回归问题，从像素中能够直接提取边界框的四个顶点以及分类的概率值。使用我们的系统，你只需要看一次（you only look once）图片就能够预测物体是什么，它们在图像的什么位置。

YOLO不可思议的简单：如图1所示。只用一个卷积网络来同时预测多个边界框以及分类的置信度。YOLO使用整个图像来进行训练，并且直接以训练的结果作为优化。这个统一的模型相对于传统的目标检测算法有许多优势。

首先，YOLO非常快。因为我们将目标检测任务构建为一个回归问题，我们不需要一个复杂的管道。我们只需要在测试时将我们的神经网络跑在一张新的图片上来预测分类结果。我们的网络，在Titan X GPU环境下，基础版本的YOLO可以达到45帧每秒，而快速版本的则可以达到超过150帧每秒。这就意味着我们可以实时处理视频流，并且延迟低于25毫秒。另外，YOLO的平均测量精度是别的系统的两倍。如果想看我们的系统的实时演示的demo，请点击这个网站：

https://pjreddie.com/darknet/yolo/。

其次，YOLO在做预测时，考虑到了整个图像。不像滑动窗口和候选区域的方法，YOLO在训练和测试时考虑到了整个图像，所以（训练出的网络）间接地包含了物体的上下文信息。Fast R-CNN，一个顶尖的目标检测方法，经常将背景误认为是目标，因为它不能看到更多的上下文信息。YOLO则不然。将背景误识别的概率，YOLO是Fast R-CNN的一半。

最后，YOLO学习物体的表示与生成方法。当在自然图像上训练，并且在人工的艺术品上检测时，YOLO的检测效果远比顶尖的目标检测算法，例如DPM和R-CNN要好。因为YOLO是高度生成的，所以当存在一个新领域的未知的输入时，YOLO崩溃的可能性更小。

尽管有这么多优点，YOLO仍然比目前精度最高的目标检测算法精度低。虽然它能够迅速地识别图像中的物体，但是它在精确定位上有一些困难，尤其是一些较小的物体。我们会在之后的实验中检验速度与精度的关系。

我们的所有训练与测试的代码都是开源的。一些预训练模型也提供下载。

\section{统一检测}

我们将目标检测的多个任务统一进了一个神经网络。我们的网络使用整个图像的特征来预测每个边界框。该网络还同时对每个边界框里的物体进行分类。这就意味着我们的网络感知整个图像以及图像中的物体。YOLO的设计实现了端到端的训练和实时的检测速度，同时还保有较高的准确率。

我们的系统将输入的图像分割为$S\times X$个栅格。如果物体的中心落入了栅格中，那么这个栅格就负责检测这个物体。

每个栅格都预测B个边界框以及这些边界框的置信度。这些置信度分数反映了模型有多确信这些边界框内包含物体，以及这些边界框有多准确。我们定义置信度为$Pr(Object)*IOU^{truth}_{pred}$。如果在栅格中没有物体存在，则该置信度应该为0。否则其置信度应该等于预测边界框与真值的边界框的重叠面积占比（intersection over union）。

每个边界框需要预测的参数有五个：$x,y,w,h$和置信度。$(x,y)$坐标表示边界框的中心相对于栅格的边界的位置。宽度和高度则是相对于整个鱼香而言。最后，预测的置信度表示预测的边界框与真实的边界框之间的IOU得分。

每个栅格同时预测C个可能类别，$Pr(Class_i|Object)$。我们只计算那些有物体的栅格的概率，我们也对每个栅格预测一系列类别，而不管边界框B的数目。