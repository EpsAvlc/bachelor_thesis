% !Mode:: "TeX:UTF-8"


\chapter{点云和图像的多感知融合}
根据本文第二章所提到的机构，能够将三维激光雷达在其俯仰角方向上提供一个有规律的正弦往复运动。本文提出该机构的主要目的为将激光雷达在时间轴上的多帧点云进行配准，进而增加激光雷达在竖直方向的分辨率。本章将对第二章所述的三维感知机构得到多帧激光雷达点云进行融合，并且在目前机构的基础上进行激光雷达与相机的标定，从而使得融合后的点云能够应用于后文提到的基于视觉与激光融合的三维障碍物检测方法。

\section{激光雷达点云的多帧融合}

\subsection{一种朴素的多帧融合策略}
点云的配准（registration）是指将有重合部分的点云进行对齐的一项技术。其关键核心为求出给定点云的坐标系相对于目标点云所在坐标系的旋转与平移，借以将给定点云转换到目标点云坐标系中。

\pic[htbp]{三维感知机构的旋转}{width=1\textwidth}{rotation}

如图\ref{rotation}所示，本文认为当激光雷达俯仰角与地面平行时，其激光雷达坐标系为参照系$f$，第二章所述的三维感知机构目的就在于在激光雷达做往复运动时，将激光雷达每帧点云在参照系$f$上进行配准，最后在曲柄机构的一个运动周期后将点云融合输出。当机构运动时，激光雷达自身坐标相对于$f$发生了旋转，因而在激光雷达坐标系中的点云相对于$f$有一个$\alpha$角度的旋转量。因而要将此时的点云配准到$f$坐标系中时，要抵消因机构旋转而造成的坐标系的旋转。最为直观的策略就是，读取绝对值编码器返回的角度$\alpha$，将激光雷达每帧点云沿着俯仰角方向旋转$-\alpha$的角度，然后配准多帧的激光雷达点云并发布。

在实际的实现过程中，编码器返回角度的频率约为30Hz，而点云发布的频率约为10Hz。为了对角度信息进行线性插值，将角度信息保存到一个队列$Q$中，同时在接收到新的点云信息时，根据点云的时间戳$t_{lid}$，在队列$Q$中寻找相邻两帧角度信息，记这两帧角度信息的时间戳为$t_{enc}^0, t_{enc}^1$，则这两帧信息应满足$t_{enc}^0 \leq t_{lid} \leq t_{enc}^1$。那么$t_{lid}$时刻的角度值由下式线性插值得到：
\begin{equation}
    \alpha = \alpha_0+(\alpha_1-\alpha_0)\times \frac{t_{lid} - t_{enc}^0}{t_{enc}^1 - t_{enc}^0}
\end{equation}
同时，根据计算曲柄机构的角度是增加还是减少，来判断曲柄机构的运动方向，并且将曲柄机构一个往复运动周期内的点云融合为一帧新的点云输出。

然而这种朴素的融合策略在实际中效果不好，体现在融合后的点云所显示的物体轮廓失真严重，如图\ref{car_before}所示，原因是没有考虑激光雷达的运动对激光雷达点云生成的影响。

\subsection{点云的运动畸变的形成与矫正}
在激光雷达点云的多帧融合中，如果只是进行简单的历史点云叠加（如上文所述），那么融合后的点云相较于真实情况会有很严重的失真，其原因就在于第二章所提到的三维感知机构在给激光雷达在偏航角方向上的往复运动时，点云会产生不可忽视的运动畸变。本章节首先介绍什么是激光雷达点云的运动畸变，然后提出一种通过插值的方式矫正激光雷达的运动畸变。

\subsubsection{点云的运动畸变}
激光雷达的点云的形成本质上是由激光雷达内部的多个激光测距器将一个旋转周期内的各个测量值记录下来并同时发布后得到的。因此点云中的每个点并不是在同一时刻被测量出来的。如果激光雷达在测量的过程中也在运动，那么激光雷达的点云可能会发生畸变\citeup{hong2010vicp}。

下面以二维激光雷达为例，介绍激光雷达点云运动畸变的形成。
\begin{pics}[htbp]{激光雷达运动畸变}{distort}
    \addsubpic{ground truth}{width=0.3\textwidth}{distortion_groundtruth}
    \addsubpic{采集得到的数据}{width=0.3\textwidth}{distortion}
\end{pics}
图\ref{distortion_groundtruth}中的黑色的线条表示二维激光雷达处在的真实环境的轮廓图，箭头表示二维激光雷达的运动方向。图\ref{distortion}中的蓝色的线条表示二维激光雷达的原始数据。注意到其已经发生了畸变，因为二维激光雷达内的激光测距器通过逆时针的方向旋转，使得右上角的数据优先得到，而左上角的数据在激光雷达向箭头方向运动了一段距离之后才进行测量，自然导致了运动畸变的产生。

值得一提的是上图表示的二维激光雷达发生的运动畸变是当激光雷达运动方向为水平运动方向时造成的，而当激光雷达在空间中有垂直方向的旋转运动时，其造成的运动畸变远比水平运动严重。这是因为激光雷达旋转一周的时间普遍在0.1秒左右，其水平运动的距离往往很小可以忽略不计。而当激光雷达有竖直方向的旋转时，即使在0.1s内只有2度的俯仰角的旋转（这在本文的机构运动中并不算很快），在测量20m处的物体时，其运动造成的点云畸变可使得点云的同一线上的第一个点与最后一个点的垂直距离相差将近70cm。

综上所述，对于第二章所述的机构，由于其施加了在激光雷达俯仰角方向上的旋转，因此导致其在竖直方向上的运动畸变不可忽视，从而简单的叠加点云会导致在做激光雷达的物体检测时的失真。

\subsubsection{运动畸变的矫正}

对于本文所提到的三维感知机构在俯仰角方向上的旋转所产生的运动畸变的矫正，一个较为直观的方法是，依次遍历激光雷达每帧点云中的每个点，计算其产生的时间戳$t$，对磁编码器的角度进行插值，计算出在时间戳$t$上的角度$\alpha$，然后将该点绕原点在俯仰角方向旋转$-\alpha$的角度。然而激光雷达每帧点云高达数十万个点，如果对每个测量得到的点进行插值，则在一秒内要进行近百万次的插值与旋转操作，显然对于无人驾驶汽车上的移动处理器平台来说这是不现实的。

因此本文提出一个折中的假设，设点云中第一个点产生的时间戳为$t_0$，最后一个点产生的时间戳为$t_k$，则将$t_0$到$t_k$之间的时间均匀分为$n$份，每份长为$\Delta t$。本文假设每个$\Delta t$时间段内的激光雷达的测距点的产生的时间都是相同的，为其第一个点的产生时间。根据这个假设，每个时间段内的所有点都只要进行相同角度变换即可进行运动畸变的矫正。遵循该假设，则每帧点云只需要进行n次角度插值即可，极大地减小了运算量。同时虽然该假设认为同一时间段内的点云是同一时间产生的，每个时间段内的点仍有运动畸变的影响，然而在实验过程中发现，只要当$n$取一个不太小的值（$n\geq 50$），则该假设的所产生的时间段内的运动畸变产生的影响很小，可忽略不计。

在实际的程序实现中，由于激光雷达每帧点云是分段传输的，如图\ref{udp_packet}所示。
\pic[htbp]{点云的传输}{width=0.6\textwidth}{udp_packet}
RS-LiDAR-16激光雷达采用UDP协议向PC传输点云信息，而UDP协议相较于TCP协议，发送数据之前不需要双方建立链接，并且发送的数据没有校验，也没有丢包的检测，因此不适合一次性发送大量数据给PC。该激光雷达将一帧点云分为84个 UDP包(UDP Packet)，每个包中的点云都是激光雷达旋转$360 / 84 = 4.28$度后得到的16线的点云的集合。当激光雷达的驱动程序接收到84个UDP Packet之后，将这84 个Packet合并成一帧点云输出。

本文直接对每个Packet（而不是每帧）分别进行编码器角度的插值与点云的旋转，最后再将旋转后的84个Packet进行合并发布。这样相对于之前提到的朴素的融合方法，每帧帧内多进行了84次线性插值，从而大大减小了相机运动畸变带来的影响。

\subsection{矫正运动畸变后的多帧融合策略}

如上文所言，对单帧点云进行多次插值之后的多帧融合算法流程如Algorithm~\ref{fusion_algorithm}所示。
$\\$
\begin{algorithm}[ht]
    \caption{Improved multiple pointcloud fusion algorithm} %算法的名字
    \label{fusion_algorithm}
    \begin{algorithmic}[1]
    % \State some description % \State 后写一般语句
    \For{packet $\in$ point cloud} % For 语句，需要和EndFor对应
        \State $\alpha_1$, $\alpha_2$ = FindeClosestAngles(encorderAngles, packet.timestamp)
    　　 \State $\alpha$ = $\alpha_1+(\alpha_2-\alpha_1)\times \frac{packet.timestamp - \alpha_1.timestamp}{\alpha_2.timestamp - \alpha_1.timestamp}$
        \State rectifiedPacket = RotatePointCloudByYaw(packet, $-\alpha$)
        \State rectifiedPointcloud += rectifiedPacket
    \EndFor
    \State \Return rectifiedPointcloud
    \end{algorithmic}
\end{algorithm}

在Algorithm~\ref{fusion_algorithm}中，FindeClosestAngles函数查找在所有的编码器角度中，时间上离packet的时间戳最近的两帧编码器的角度值，随后对这两个角度进行线性插值得到packet时间戳下的机构的角度。RotatePointCloudByYaw函数将特定的点云绕激光雷达坐标系原点旋转指定的角度。最后将每个矫正后的packet合并到一个新的矫正后的点云中并发布出去即得到了矫正因机构而产生的运动畸变后的点云。

在图\ref{car_after}中展示了消除运动畸变后的激光雷达测得的轿车的点云图案。相较于图\ref{car_before}，其点云图案没有出现明显的失真，并且通过机构进行多帧融合后的点云，能够明显的看出轿车的轮廓细节信息，包括车的反光镜、前挡风玻璃等。而矫正畸变前的轿车点云则很难分辨出这些细节，并且由于运动畸变的作用，其体积明显比矫正后的点云更大一些。由此证明了本文提出的多帧融合算法拥有较好的矫正畸变的效果。

为了显示畸变矫正后的对比效果，本文还挑选了离激光雷达较远的建筑物上的窗户的点云的矫正机变的前后对比图，如图\ref{window_before}，\ref{window_after}所示。当距离较远时，运动畸变的作用会被放大，然而从图中可以看出，经过畸变矫正后的点云，仍然拥有较为不错的细节丰富程度。
\begin{pics}[htbp]{多帧融合后的轿车点云}{distort_remove}
    \addsubpic{矫正畸变前}{width=0.4\textwidth}{car_before}
    \addsubpic{矫正畸变后}{width=0.4\textwidth}{car_after}
\end{pics}


\begin{pics}[htbp]{多帧融合后的窗户点云}{distort_remove}
    \addsubpic{矫正畸变前}{width=0.444\textwidth}{window_before}
    \addsubpic{矫正畸变后}{width=0.4\textwidth}{window_after}
\end{pics}

\section{激光雷达与相机的标定}

自动驾驶无人车是一个多传感器的系统，多传感器信息的融合可以使整个无人车系统的决策更加智能。激光雷达虽然能够获取较为精确的点云信息，然而点云信息只包含了三维距离信息。而相机可以通过图像获得大量信息诸如颜色、纹理信息等，但是其受光照与天气条件影响严重，并且从单目图像中无法获取三维结构信息。为了同时收集三维信息与物体的颜色与纹理信息，激光雷达与相机经常进行传感器的数据融合，来为多传感器系统提供更稳定的数据支持。为了进行数据的融合，首先得知道相机坐标系与激光雷达坐标系之间的旋转与平移关系，因此，激光雷达与相机的标定就显得尤为重要了。

本章节后续将介绍一种文献\citeup{dhall2017lidar}提到的,利用两张贴有ArUco Marker\citeup{garrido2014automatic}的标定板所提供的3d-3d特征匹配的方法，来进行相机与激光雷达的标定。

\subsection{标定板}
\pic[htbp]{标定环境}{width=0.6\textwidth}{calib_board}

本文参照文献\citeup{dhall2017lidar}提到的方法，制作了两块长约40cm，宽约27cm的长方形硬纸板材质的标定板，并且将两块ArUco Marker粘在硬纸板的固定位置上，如图\ref{calib_board}所示。虽然一块标定板已经可以得到四组3d-3d匹配点来解决标定问题，本文仍然采用了两块标定板，目的是构造多于四对的匹配点来减小标定误差。

\subsection{相机坐标系中的三维特征点提取}

ArUco markers是一种经过特定编码的二维码图案，用以实现对二维码自身的定位与畸变矫正。更多细节可以参考文献\citeup{garrido2014automatic}。该文献提出，通过特定的机器视觉算法检测到marker的四个角点后，可以对marker上的二维码进行解码运算，进而求得二维码的id与四个角点的顺序。而通过输入marker的边长后，还能够通过PnP\citeup{Lepetit2008}求解出相机坐标系到marker自身坐标系的转换。

\pic[htbp]{ArUco markers}{width=0.3\textwidth}{aruco_markers}

在本文中，将ArUco marker粘在硬纸板的矩形标定板上，并且测量得出硬纸板的四条边长以及marker在硬纸板中的位置，即可得到硬纸板的四个角点在marker 坐标系中的位置。而本文通过ROS中aruco\_ros以及aruco\_mapping\citeup{Bacik2016aruco}两个程序包可以检测ArUco marker的位置，进而得到相机坐标系到marker坐标系的转换，从而得到相机坐标系下的硬纸板的四个角点的位置。相机坐标系下角点位置的计算公式为

\begin{equation}
\begin{bmatrix} x_{camera}\\y_{camera}\\z_{camera}\\ 1 \end{bmatrix}\quad = \begin{bmatrix} R_{11}&R_{12}&R_{13}&t_x\\R_{21}&R_{22}&R_{23}&t_y\\R_{31}&R_{32}&R_{33}&t_z\\ 0&0&0&1 \end{bmatrix}\quad \begin{bmatrix} x_{aruco}\\y_{aruco}\\z_{aruco}\\ 1 \end{bmatrix}\quad
\end{equation}
    
其中，$x_{camera}$是相机坐标系中角点的坐标，$x_{aruco}$是ArUco marker坐标系中的角点坐标，而上式中的$[R|t]$矩阵则是相机坐标系相对于marker坐标系的欧氏变换矩阵。

\subsection{LiDAR坐标系中的三维特征点提取}

本文所参照的标定方法，其在LiDAR坐标系中的三维特征点提取是通过直线拟合的方法进行的。如图\ref{line_fitting}所示。图中显示的点为激光雷达的点云投影到相机图像上之后进行边缘检测后所形成的点。在得到该幅图像后，需要手动框选标定板的每条边上的点，随后标定程序会对这些点进行直线拟合，每两条直线的交点即为所求的LiDAR坐标系中的三维点。

\pic[htbp]{直线拟合提取特征点}{width=0.8\textwidth}{line_fitting}
\subsection{坐标系欧氏变换求解}

在得到两个坐标系下的三维特征匹配点之后，两个坐标系之间的$[R|t]$欧氏变换 Closest Point, ICP）\citeup{Zhang1994Iterative}算法求得。假设$P$，$Q$为$\mathbb{R}^3$中的一组对应点，ICP算法尝试使经过欧氏变换后的P点集与Q点集的重合误差最小。其求解问题可以表述为式\ref{eq:ICP}所示。
\begin{equation}
    \mathop{\arg\min}_{R\in SO(3), t\in \mathbb{R}^3}  \| (RP+t)-Q \|^2 
    \label{eq:ICP}
\end{equation}
一般来说，ICP问题认为对于点集$P$中的每个点，在点集$Q$中与之对应的点为其距离最近的点，依次确认匹配关系后，该算法通过减小两个点集的欧氏距离来对齐两个点集。

ICP的方法找到两组点的匹配关系，在没有良好的初始值的情况下，极易发生误匹配，导致算法最后没办法收敛到一个正确的解。考虑到在本文的标定环境下，两组点的对应关系的是已知的，则两组点之间的$[R|t]$即存在一个闭式解。Kabsch算法\citeup{kabsch1976solution}\citeup{sorkine2009least}提供了找到两组对应点间的旋转矩阵的闭式解的方法，而两组点间的平移量可以在进行旋转对齐后求得。下面参照文献\citeup{sorkine2009least}，介绍Kabsch算法的主要步骤。

首先假设旋转已知，求两个点集$P$与$Q$之间的平移量，设
\begin{equation}
    F(t) = \sum_{i=1}^n{\|(RP_i + t)-Q_i \|}^2
    \label{eq:k1}
\end{equation}
对上式进行求导，令两边等于0，得
\begin{equation}
    \frac{\partial F(t)}{\partial t}=2\sum_{i=1}^n{((RP_i + t)-Q_i)}=0
\end{equation}
因为
\begin{equation}
    \frac{\partial F(t)}{\partial t}=2R\sum_{i=1}^n{P_i} +2nt - 2\sum_{i=1}^n{Q_i}
\end{equation}
可得
\begin{equation}
    t = \frac{1}{n}\sum_{i=1}^n{Q_i}-R\frac{1}{n}\sum_{i=1}^n{P_i}
\end{equation}
\begin{equation}
    t = \overline{Q}-R\overline{P}
    \label{eq:k2}
\end{equation}
将式\ref{eq:k2}的结果代入式\ref{eq:k1}中，有
\begin{equation}
    R = \mathop{\arg\min}_{R \in SO(3)} \sum_{i=1}^n\|(R(P_i - \overline{P})-(Q_i - \overline{Q}))\|^2
\end{equation}
令
$$
    X = P_i - \overline{P}, X' = RX, Y= Q_i - \overline{Q}
$$
则目标函数可化简为
\begin{equation}
    \sum_{i=1}^n {\|X_i' - Y_i\|}^2=Tr((X'-Y)^T(X'-Y))
\end{equation}
其中$X_i', Y_i$是点集$X', Y$中的点。
使用矩阵的迹的性质，上式可化简为
\begin{equation}
    Tr((X'-Y)^\mathrm{T}(X'-Y)) = Tr({X'}^{T}X') + Tr(Y^{T}Y) - 2Tr(Y^{T}X)
\end{equation}
考虑到$R$是一个旋转矩阵，旋转矩阵必定正交且行列式为1，也就是说，$\|{X'}_i\|^2 = \|X_i\|^2 $，则有
\begin{equation}
    Tr((X'-Y)^\mathrm{T}(X'-Y)) = \sum_{i=1}^n {(|X_i|^2 +|ｙ_i|^2)}- 2Tr(Y^{T}X)
\end{equation}
可知$\sum_{i=1}^n {(|X_i|^2 +|ｙ_i|^2)}$项与旋转矩阵$R$无关，将其从目标函数中消去，有
\begin{equation}
    R = \mathop{\arg\min}_{R \in SO(3)} Tr(Y^TX')
\end{equation}
将$X'=RX$代入，并利用矩阵迹的性质，有
\begin{equation}
    Tr(Y^TX')=Tr(Y^TRX)=Tr(XY^TR)
\end{equation}
对$XY^T$进行SVD分解，有$XY^T=UDV^T$，则
\begin{equation}
    Tr(XY^TR)=Tr(UDV^TR)=Tr(DV^TRU)=\sum_i^3{d_iv_i^TRu_i}
\end{equation}
令$M=V^TRU$，则$M$由正交矩阵相乘而得，故易知其亦为正交矩阵，并且$det(M)=\pm 1$。因此M的每个列向量的模均为1，列向量的每个元素均小于等于1。则有
\begin{equation}
    Tr(XY^TR)=\sum_i^3{d_i M_{ii}} \leq \sum_i^3{d_i}
\end{equation}
令上式值最大，则得到$M_{ii}=1$，因此$M=I$，为单位矩阵。有
\begin{equation}
    M=I\Rightarrow V^TRU=I \Rightarrow R=VU^T
\end{equation}
需要注意的是，$R$应当是一个旋转矩阵，也就是说，$R \in SO(3)$，所以应当确保 $det(R)=+1$。如果由上式得到的$R$，其特征值为-1，则其为不满足条件的解，需要找到使$Tr(Y^TX')$第二大的R，即
\begin{equation}
    Tr(Y^TX')=d_1M_{11}+d_2M_{22}+d_3M_{33}\ \ where\ \ d1\geq d2 \geq d3 \ \ and\ \ |M_{ii}| \leq 1
\end{equation}
在上式中，当$M_{11}=M_{22}=1$且$M_{33}=-1$时，该式值第二大。将上述情况考虑进去，则$R$的闭式解为$R=UCV^T$，其中C为一个矫正矩阵，
$$
C=\begin{bmatrix} 1&0&0 \\ 0&1&0 \\ 0&0&sign(det(UV^T))
\end{bmatrix}
$$

\subsection{多帧坐标系变换结合}
在实验中发现，由相机图像求得的三维特征点比较稳定，而由于激光雷达本身存在传感器误差，其通过直线拟合求交点得到的三维角点不够稳定，在相机与激光雷达位置均固定的情况下，每次测得的激光雷达测得的三维特征角点在会有一个较小的位移，而这样的位移会对用Kabsch算法得到的解产生较大的误差。

为了减小因激光雷达传感器误差而造成的三维特征角点不准确的问题，本文在相机与激光雷达位置固定的情况下，针对多帧图像与点云进行了匹配运算，对$N$次结果进行求取平均值。对平移量的平均值求取公式为
$$\overline{t}=\frac{1}{N}\sum_{i=1}^N{{tvec}_i}$$
而对于旋转量的求取平均值，先将上文求得的旋转转为四元数${rvec}_i$形式，再对四元数求取平均值。
$$r=\frac{1}{N}\sum_{i=1}^N{{rvec}_i}$$
$$\overline{r}=\frac{r}{\|r\|}$$

通过对多帧激光雷达点云与相机进行三维点匹配得到的欧氏变换求取平均值，能够有效的抑制因激光雷达的传感器误差而造成的标定误差。

\section{点云与图像的融合}

本章所述的传感器设置如图\ref{sensors_setup}所示。其中激光雷达坐标系到相机坐标系的欧氏变换已由第二章介绍的标定方法得到。在介绍如何将激光雷达点云投影到相机图像上之前，本文将先介绍相机的成像原理，这是点云投影的理论基础。

\pic[htbp]{传感器设置}{width=1\textwidth}{sensors_setup}

\subsection{相机成像原理}

所谓的相机成像，就是相机将三维空间中的坐标映射到二维图像平面的过程。
这一映射可以有许多数学模型去解释，最简单也最为常用的就是针孔成像模型，如图\ref{pinhole}所示。
\pic[htbp]{相机针孔成像原理}{width=1\textwidth}{pinhole}
现在对该模型进行建模。设图中$O-x-y-z$为相机坐标系。通常认为相机坐标系$Z$轴指向相机的前方，$X$轴指向右方，$Y$轴指向下方。设真实空间中有一三维点$P$，经过相机的小孔$O$成像后，成像点落在相机的成像平面$P'$处，设$P$点的坐标为$[X, Y, Z]^T$，$P'$点的坐标为$[X', Y', Z']$，并且设相机的成像平面到模型中的针孔的距离为$f$（焦距）,则根据三角形的相似关系，有
\begin{equation}
    \frac{Z}{f}=-\frac{X}{X'}=-\frac{Y}{Y'}
\end{equation}
整理得
\begin{equation}
\left\{
    \begin{split}
        X'=f\frac{X}{Z} \\
        Y'=f\frac{Y}{Z}  
    \end{split}
\right.
\label{eq:pinhole}
\end{equation}

实际上，在相机中最后得到的是一个个的像素，设在相机成像平面上存在一个像素平面$O-u-v$，$P'$在像素平面的坐标为$[u,v]^T$。像素坐标系通常定义其原点$O'$在图像的左上角，其$u$轴与$v$轴的方向与相机坐标系中的$X$轴与$Y$轴相同。像素坐标系相对于相机坐标系，相差了一个平移与缩放。假设相机坐标系在$u$轴上缩放了$\alpha$倍，在$v$轴上缩放了$\beta$倍，同时像素坐标系相对于相机坐标系的原点平移了$[c_x, c_y]^T$。则$P'$在成像平面上的坐标与其像素坐标$[u,v]^T$之间的关系为
\begin{equation}
    \left\{
        \begin{split}
            u = \alpha X' + c_x \\
            v = \beta Y' + c_y
        \end{split}
    \right.
\end{equation}
将上式代入式\ref{eq:pinhole}中，并设$\alpha f = f_x$，$\beta f = f_y$，则有
\begin{equation}
    \left\{
        \begin{split}
            u = f_x \frac{X}{Z} + c_x \\
            v = f_y \frac{Y}{Z} + c_y
        \end{split}
    \right.
\end{equation}

将上式写为矩阵的形式，则有
\begin{equation}
    \begin{bmatrix} u \\ v \\ 1
    \end{bmatrix}
    = \frac{1}{z} \begin{bmatrix} fx & 0 & cx \\ 0 & fy & cy \\ 0 & 0 &1 
    \end{bmatrix}
    \begin{bmatrix} X \\ Y \\ Z
    \end{bmatrix}
    \triangleq \frac{1}{Z}KP
    \label{camera_calib_eq}
\end{equation}
其中矩阵$\begin{bmatrix} fx & 0 & cx \\ 0 & fy & cy \\ 0 & 0 &1 
\end{bmatrix}$称之为相机的内参，通常，相机的标定就是为了得出相机的内参矩阵。本文在融合激光与相机之前已通过ROS的标定程序得到了相机的内参$K$。

\subsection{激光雷达点云的投影}

式\ref{camera_calib_eq}中，$P$为相机坐标系内的一点，所以在根据第二章得到的标定方法得出激光雷达与相机坐标系的变换矩阵$T$后，先将激光雷达点云转换到相机坐标系中，再通过内参矩阵投影到图像上，即
\begin{equation}
    P_{uv} = \frac{1}{Z} KTP_{LiDAR}
\end{equation}
其中$P_{LiDAR}$表示激光雷达坐标系中的点云中的三维点。
\pic[htbp]{激光雷达点云的投影}{width=1\textwidth}{projection}

本文利用前文提到的三维感知机构进行了多帧点云的融合配准，并将融合后的点云投影到了相机的图像上，点云投影效果如图\ref{projection}所示。其中投影点的颜色越深，代表其距离相机的位置越近；颜色越浅，代表离相机的距离越远。在将激光雷达点云投影到图像之后，便可以利用YOLO的检测结果对点云进行分割与分类。

\section{本章小结}

本章介绍了什么是激光雷达点云配准与运动畸变，并且提出了插值矫正运动畸变的方法：在对点云进行多帧融合时，利用点云传输的特性，将点云在时间上为84个Packet单独发布，同时线性插值得到这些Packet的时间戳上的编码器角度值，将这些Packet点云依据编码器的角度配准到参考坐标系中，并且将所有的Packet点云进行叠加配准后发布为新的点云。由于对每帧点云多进行了84次旋转角度的插值，从点云图案上看，本文提到的方法极大地改善了运动畸变对点云配准的影响，完成了矫正运动畸变的目的。同时，本章还介绍了一种利用特制的标定板在相机与激光雷达坐标系中寻找三维特征匹配点的方法来进行相机的标定，并详细介绍了如何利用三维匹配点来计算出两个点集所在的坐标系之间的欧氏变换（Kabsch算法）。本文还根据得到的欧氏变换矩阵，将激光雷达的点云与相机的图像进行了融合。在后续的章节，本文将基于传感器融合后的结果进行三维障碍物的分割与分类。