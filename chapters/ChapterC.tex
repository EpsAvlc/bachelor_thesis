% !Mode:: "TeX:UTF-8"


\chapter{点云的多帧融合与激光雷达和相机标定}
根据本文第二章所提到的机构，能够将三维激光雷达在其yaw角方向上提供一个有规律的正弦往复运动。本文提出该机构的主要目的为将激光雷达在时间轴上的多帧点云进行融合，进而增加激光雷达在竖直方向的分辨率，达到近似于给激光雷达增加线数的效果。本章将对上述机构得到多帧激光雷达点云进行融合，并且在目前机构的基础上进行激光雷达与相机的标定，从而使得融合后的点云能够应用于第四章提到的基于视觉与激光融合的三维障碍物检测方法。

\section{激光雷达点云的多帧融合}

\subsection{一种朴素的多帧融合策略}
点云的注册（registration）是指将有重合部分的点云进行对齐的一项技术。其关键核心为求出给定点云的坐标系相对于目标点云所在坐标系的旋转与平移，借以将给定点云转换到目标点云坐标系中，丰富目标点云的信息，以给之后的点云分割与分类任务提供便利。

\pic[htbp]{三维感知机构的旋转}{width=1\textwidth}{rotation}

如图\ref{rotation}所示，本文认为当激光雷达航向角与地面平行时，其激光雷达坐标系为参照系$f$，第二章所述的三维感知机构目的就在于在激光雷达做往复运动时，将激光雷达每帧点云在参照系$f$上进行注册，最后在曲柄机构的一个运动周期后将点云融合输出。当机构运动时，激光雷达自身坐标相对于$f$发生了旋转，因而在激光雷达坐标系中的点云相对于$f$有一个$\alpha$角度的旋转量。因而要将此时的点云注册到$f$坐标系中时，要抵消因机构旋转而造成的坐标系的旋转。

最为直观的策略就是，读取绝对值编码器返回的角度$\alpha$，将激光雷达每帧点云沿着航向角方向旋转$-\alpha$的角度，然后注册多帧的激光雷达点云并发布。

在实际的实现过程中，编码器返回角度的频率约为30Hz，而点云发布的频率约为10Hz，在将点云旋转$-\alpha$角度时，对$\alpha$角进行了线性插值以便获得更加精确的结果。同时，根据计算曲柄机构的角度是增加还是减少，来判断曲柄机构的运动方向，并且将曲柄机构运动角度为一个正弦周期内的点云融合为一帧新的点云输出。

然而这种朴素的融合策略在实际中效果不好，体现在融合后的点云所显示的物体轮廓失真严重，如图\ref{car_before}所示，原因是没有考虑激光雷达的运动对激光雷达点云生成的影响。

\subsection{点云的运动畸变的形成与矫正}
在激光雷达点云的多帧融合中，如果只是进行简单的历史点云叠加（如上文所示），那么融合后的点云相较于真实情况会有很严重的失真，其原因就在于第二章所提到的三维感知机构在给激光雷达在偏航角方向上的往复运动时，点云会产生不可忽视的运动畸变。本章节首先介绍什么是激光雷达点云的运动畸变，然后提出一种通过插值的方式矫正激光雷达的运动畸变。

\subsubsection{点云的运动畸变}
激光雷达的点云的形成本质上是由激光雷达内部的多个激光测距器将一个旋转周期内的各个测量值记录下来并同时发布后得到的。因此点云中的每个点并不是在同一时刻被测量出来的。如果激光雷达在测量的过程中也在运动，那么激光雷达的点云可能会发生畸变\citeup{hong2010vicp}。

下面以二维激光雷达为例，介绍激光雷达点云运动畸变的形成。

\begin{pics}[htbp]{激光雷达运动畸变}{distort}
    \addsubpic{ground truth}{width=0.3\textwidth}{distortion_groundtruth}
    \addsubpic{采集得到的数据}{width=0.3\textwidth}{distortion}
\end{pics}

图\ref{distortion_groundtruth}中的黑色的线条表示二维激光雷达处在的真实环境的轮廓图，箭头表示二维激光雷达的运动方向。图\ref{distortion}中的蓝色的线条表示二维激光雷达的原始数据。注意到其已经发生了畸变，因为二维激光雷达内的激光测距器通过逆时针的方向旋转，使得右上角的数据优先得到，而左上角的数据在激光雷达向箭头方向运动了一段距离之后才进行测量，自然导致了运动畸变的产生。

值得一提的是上图表示的二维激光雷达发生的运动畸变是当激光雷达运动方向为水平运动方向时造成的，而当激光雷达在空间中有垂直方向的旋转运动时，其造成的运动畸变远比水平运动严重。这是因为激光雷达旋转一周的时间普遍在0.1秒左右，其水平运动的距离往往很小可以忽略不计。而当激光雷达有竖直方向的旋转时，即使在0.1s内只有2度的航向角的旋转（这在本文的机构中并不算很快），在测量20m处的物体时，其运动造成的点云畸变可使得点云的同一线上的第一个点与最后一个点的垂直相差将近70cm。

综上所述，对于第二章所述的机构，由于其施加了在激光雷达航向角方向上的旋转，因此导致其在竖直方向上的运动畸变不可忽视，从而简单的叠加点云会导致在做激光雷达的物体检测时的失真。

\subsubsection{运动畸变的矫正}

对于本文所提到的三维感知机构在航向角方向上的旋转所产生的运动畸变的矫正，一个较为朴素的方法是，依次遍历激光雷达每帧点云中的每个点，计算其产生的时间戳$t$，对磁编码器的角度进行插值，计算出在时间戳$t$上的角度$\alpha$，然后将该点绕原点在航向角方向旋转$-\alpha$的角度。这个方法最为直观，然而激光雷达每帧点云高达数十万个点，如果对每个测量得到的点进行插值，则在一秒内要进行近百万次的插值与旋转操作，显然对于无人驾驶汽车上的移动处理器平台来说这是不现实的。

因此本文提出一个假设，设点云中第一个点产生的时间戳为$t_0$，最后一个点产生的时间戳为$t_k$，则将$t_0$到$t_k$之间的时间均匀分为$n$份，每份长为$\Delta t$。本文假设$t_0$至$t_0+\Delta t$、$t_0+\Delta t$至$t_0+2\Delta t$...$t_k-\Delta t$至$t_k$这些时间段，每个时间段内的激光雷达的测距点的产生的时间都是相同的，为其第一个点的产生时间。根据这个假设，每个时间段内的所有点都只要进行相同角度变换即可进行运动畸变的矫正。遵循该假设，则每帧点云只需要进行n次角度插值即可，极大地减小了运算量。同时虽然该假设认为同一时间段内的点云是同一时间产生的，每个时间段内的点仍有运动畸变的影响，然而在实验过程中发现，只要当$n$取一个不太小的值（$n\geq 50$），则该假设的所产生的时间段内的运动畸变产生的影响很小，可忽略不计。

在实际的程序实现中，由于激光雷达每帧点云是分段传输的，如图\ref{udp_packet}所示。
\pic[htbp]{点云的传输}{width=0.6\textwidth}{udp_packet}
RS-LiDAR-16激光雷达采用UDP协议向PC传输点云信息，而UDP协议相较于TCP协议，发送数据之前不需要双方建立链接，并且发送的数据没有校验，也没有丢包的检测，因此不适合一次性发送大量数据给PC。该激光雷达将一帧点云分为84个 UDP包(UDP Packet)，每个包中的点云都是激光雷达旋转$360 / 84 = 4.28$度后得到的16线的点云的集合。当激光雷达的驱动程序接收到84个UDP Packet之后，将这84 个Packet合并成一帧点云输出。

本文修改了RS-LiDAR-16的ROS 驱动程序，将每个UDP Packet不经过合并直接发布出去，同时在多帧融合的程序里，对每个Packet（而不是每帧）分别进行编码器角度的插值与点云的旋转，最后再将旋转后的84个Packet进行合并发布。

\subsection{矫正运动畸变后的多帧融合策略}

如上文所言，对单帧点云进行多次插值之后的多帧融合算法流程如Algorithm~\ref{fusion_algorithm}所示；。

\begin{algorithm}[t]
    \caption{Improved multiple pointcloud fusion algorithm} %算法的名字
    \label{fusion_algorithm}
    \begin{algorithmic}[1]
    % \State some description % \State 后写一般语句
    \For{packet $\in$ point cloud} % For 语句，需要和EndFor对应
        \State $\alpha_1$, $\alpha_2$ = FindeClosestAngles(encorderAngles, packet.timestamp)
    　　 \State $\alpha$ = $\alpha_1+(\alpha_2-\alpha_1)\times \frac{packet.timestamp - \alpha_1.timestamp}{\alpha_2.timestamp - \alpha_1.timestamp}$
        \State rectifiedPacket = RotatePointCloudByYaw(packet, $-\alpha$)
        \State rectifiedPointcloud += rectifiedPacket
    \EndFor
    \State \Return rectifiedPointcloud
    \end{algorithmic}
\end{algorithm}

在Algorithm~\ref{fusion_algorithm}中，FindeClosestAngles函数查找在所有的编码器角度中，时间上离packet的时间戳最近的两帧编码器的角度值，随后对这两个角度进行线性插值得到packet时间戳下的机构的角度。RotatePointCloudByYaw函数将特定的点云绕激光雷达坐标系原点旋转指定的角度。最后将每个矫正后的packet合并到一个新的矫正后的点云中并发布出去即得到了矫正因机构而产生的运动畸变后的点云。

在图\ref{car_after}中展示了消除运动畸变后的激光雷达测得的轿车的点云图案。相较于图\ref{car_before}，其点云图案没有出现明显的失真，并且通过机构进行多帧融合后的点云，能够明显的看出轿车的轮廓细节信息，包括车的反光镜、前挡风玻璃等。而矫正畸变前的轿车点云则很难分辨出这些细节，并且由于运动畸变的作用，其体积明显比矫正后的点云更大一些。由此证明了本文提出的多帧融合算法拥有较好的矫正畸变的效果。

\begin{pics}[htbp]{多帧融合后的轿车点云}{distort_remove}
    \addsubpic{矫正畸变前}{width=0.4\textwidth}{car_before}
    \addsubpic{矫正畸变后}{width=0.4\textwidth}{car_after}
\end{pics}

\section{激光雷达与相机的标定}

自动驾驶无人车是一个多传感器的系统，多传感器信息的融合可以使整个无人车系统的决策更加智能。激光雷达虽然能够获取较为精确的点云信息，然而点云信息只包含了三维距离信息。而相机可以通过图像获得大量信息诸如颜色、纹理信息等，但是其受光照与天气条件影响严重，并且从单目图像中无法获取三维结构信息。为了同时收集三维信息与物体的颜色与纹理信息，激光雷达与相机经常进行传感器的数据融合，来为多传感器系统提供更稳定的数据支持。为了进行数据的融合，首先得知道相机坐标系与激光雷达坐标系之间的旋转与平移关系，因此，激光雷达与相机的标定就显得尤为重要了。

本章节后续将介绍一种文献\citeup{dhall2017lidar}提到的,利用两张贴有ArUco Marker\citeup{garrido2014automatic}的标定板所提供的3d-3d特征匹配的方法，来进行相机与激光雷达的标定。

\subsection{标定板}
\pic[htbp]{标定环境}{width=0.6\textwidth}{calib_board}

本文参照文献\citeup{dhall2017lidar}提到的方法，制作了两块长约40cm，宽约27cm的长方形硬纸板材质的标定板，并且将两块ArUco Marker粘在硬纸板的固定位置上，如图\ref{calib_board}所示。虽然一块标定板已经可以得到四组3d-3d匹配点来解决标定问题，本文仍然采用了两块标定板，目的是构造多于四对的匹配点来减小标定误差。

\subsection{相机坐标系中的三维特征点提取}

ArUco markers是一种经过特定编码的二维码图案，用以实现对二维码自身的定位与畸变矫正。更多细节可以参考文献\citeup{garrido2014automatic}。该文献提出，通过特定的机器视觉算法检测到marker的四个角点后，可以对marker上的二维码进行解码运算，进而求得二维码的id与四个角点的顺序。而通过输入marker的边长后，还能够通过PnP\citeup{Lepetit2008}求解出相机坐标系到marker自身坐标系的转换。

\pic[htbp]{ArUco markers}{width=0.3\textwidth}{aruco_markers}

在本文中，将ArUco marker粘在硬纸板的矩形标定板上，并且测量得出硬纸板的四条边长以及marker在硬纸板中的位置，即可得到硬纸板的四个角点在marker 坐标系中的位置。而本文通过ROS中aruco\_ros以及aruco\_mapping\citeup{Bacik2016aruco}两个程序包可以检测ArUco marker的位置，进而得到相机坐标系到marker坐标系的转换，从而得到相机坐标系下的硬纸板的四个角点的位置。相机坐标系下角点位置的计算公式为
\begin{equation}
\begin{bmatrix} x_{camera}\\y_{camera}\\z_{camera}\\ 1 \end{bmatrix}\quad = \begin{bmatrix} R_{11}&R_{12}&R_{13}&t_x\\R_{21}&R_{22}&R_{23}&t_y\\R_{31}&R_{32}&R_{33}&t_z\\ 0&0&0&1 \end{bmatrix}\quad \begin{bmatrix} x_{aruco}\\y_{aruco}\\z_{aruco}\\ 1 \end{bmatrix}\quad
\end{equation}
    
其中，$x_{camera}$是相机坐标系中角点的坐标，$x_{aruco}$是ArUco marker坐标系中的角点坐标，而上式中的$[R|t]$矩阵则是相机坐标系相对于marker坐标系的欧式变换矩阵。

\subsection{LiDAR坐标系中的三维特征点提取}

本文所参照的标定方法，其在LiDAR坐标系中的三维特征点提取是通过直线拟合的方法进行的。如图\ref{line_fitting}所示。图中显示的点为激光雷达的点云投影到相机图像上之后进行边缘检测后所形成的点。在得到该幅图像后，需要手动框选标定板的每条边上的点，随后标定程序会对这些点进行直线拟合，每两条直线的交点即为所求的LiDAR坐标系中的三维点。

\pic[htbp]{直线拟合提取特征点}{width=0.8\textwidth}{line_fitting}
\subsection{坐标系欧式变换求解}

在得到两个坐标系下的三维特征匹配点之后，两个坐标系之间的$[R|t]$欧式变换矩阵可以通过使用迭代最近点（Iterative Closest Point, ICP）\citeup{Zhang1994Iterative}算法求得。假设$P$，$Q$为$\mathbb{R}^3$中的一组对应点，ICP算法尝试使经过欧式变换后的P点集与Q点集的重合误差最小。其求解问题可以表述为式\ref{eq:ICP}所示。
\begin{equation}
    \mathop{\arg\min}_{R\in SO(3), t\in \mathbb{R}^3}  \| (RP+t)-Q \|^2 
    \label{eq:ICP}
\end{equation}
一般来说，ICP问题认为对于点集$P$中的每个点，在点集$Q$中与之对应的点为其距离最近的点，依次确认匹配关系后，该算法通过减小两个点集的欧氏距离来对齐两个点集。

ICP的方法找到两组点的匹配关系，在没有良好的初始值的情况下，极易发生误匹配，导致算法最后没办法收敛到一个正确的解。考虑到在本文的标定环境下，两组点的对应关系的是已知的，则两组点之间的$[R|t]$即存在一个闭式解。Kabsch算法\citeup{kabsch1976solution}\citeup{sorkine2009least}提供了找到两组对应点间的旋转矩阵的闭式解的方法，而两组点间的平移量可以在进行旋转对齐后求得。下面参照文献\citeup{sorkine2009least}，介绍Kabsch算法的主要步骤。

首先假设旋转已知，求两个点集$P$与$Q$之间的平移量，设
\begin{equation}
    F(t) = \sum_{i=1}^n{\|(RP_i + t)-Q_i \|}^2
    \label{eq:k1}
\end{equation}
对上式进行求导，令两边等于0，得
\begin{equation}
    \frac{\partial F(t)}{\partial t}=2\sum_{i=1}^n{((RP_i + t)-Q_i)}=0
\end{equation}
因为
\begin{equation}
    \frac{\partial F(t)}{\partial t}=2R\sum_{i=1}^n{P_i} +2nt - 2\sum_{i=1}^n{Q_i}
\end{equation}
可得
\begin{equation}
    t = \frac{1}{n}\sum_{i=1}^n{Q_i}-R\frac{1}{n}\sum_{i=1}^n{P_i}
\end{equation}
\begin{equation}
    t = \overline{Q}-R\overline{P}
    \label{eq:k2}
\end{equation}
将式\ref{eq:k2}的结果代入式\ref{eq:k1}中，有
\begin{equation}
    R = \mathop{\arg\min}_{R \in SO(3)} \sum_{i=1}^n\|(R(P_i - \overline{P})-(Q_i - \overline{Q}))\|^2
\end{equation}
令
$$
    X = P_i - \overline{P}, X' = RX, Y= Q_i - \overline{Q}
$$
则目标函数可化简为
\begin{equation}
    \sum_{i=1}^n {\|X_i' - Y_i\|}^2=Tr((X'-Y)^T(X'-Y))
\end{equation}
使用矩阵的迹的性质，上式可化简为
\begin{equation}
    Tr((X'-Y)^\mathrm{T}(X'-Y)) = Tr({X'}^{T}X') + Tr(Y^{T}Y) - 2Tr(Y^{T}X)
\end{equation}
考虑到$R$是一个旋转矩阵，旋转矩阵必定正交且行列式为1，也就是说，$\|{X'}_i\|^2 = \|X_i\|^2 $，则有
\begin{equation}
    Tr((X'-Y)^\mathrm{T}(X'-Y)) = \sum_{i=1}^n {(|X_i|^2 +|ｙ_i|^2)}- 2Tr(Y^{T}X)
\end{equation}
可知$\sum_{i=1}^n {(|X_i|^2 +|ｙ_i|^2)}$项与旋转矩阵$R$无关，将其从目标函数中消去，有
\begin{equation}
    R = \mathop{\arg\min}_{R \in SO(3)} Tr(Y^TX')
\end{equation}
将$X'=RX$代入，并利用矩阵迹的性质，有
\begin{equation}
    Tr(Y^TX')=Tr(Y^TRX)=Tr(XY^TR)
\end{equation}
对$XY^T$进行SVD分解，有$XY^T=UDV^T$，则
\begin{equation}
    Tr(XY^TR)=Tr(UDV^TR)=Tr(DV^TRU)=\sum_i^3{d_iv_i^TRu_i}
\end{equation}
令$M=V^TRU$，则$M$由正交矩阵相乘而得，故易知其亦为正交矩阵，并且$det(M)=\pm 1$。因此M的每个列向量的模均为1，列向量的每个元素均小于等于1。则有
\begin{equation}
    Tr(XY^TR)=\sum_i^3{d_i M_{ii}} \leq \sum_i^3{d_i}
\end{equation}
令上式值最大，则得到$M_{ii}=1$，因此$M=I$，为单位矩阵。有
\begin{equation}
    M=I\Rightarrow V^TRU=I \Rightarrow R=VU^T
\end{equation}
需要注意的是，$R$应当是一个旋转矩阵，也就是说，$R \in SO(3)$，所以应当确保 $det(R)=+1$。如果由上式得到的$R$，其特征值为-1，则其为不满足条件的解，需要找到使$Tr(Y^TX')$第二大的R，即
\begin{equation}
    Tr(Y^TX')=d_1M_{11}+d_2M_{22}+d_3M_{33}\ \ where\ \ d1\geq d2 \geq d3 \ \ and\ \ |M_{ii}| \leq 1
\end{equation}
在上式中，当$M_{11}=M_{22}=1$且$M_{33}=-1$时，该式值第二大。将上述情况考虑进去，则$R$的闭式解为$R=UCV^T$，其中C为一个矫正矩阵，
$$
C=\begin{bmatrix} 1&0&0 \\ 0&1&0 \\ 0&0&sign(det(UV^T))
\end{bmatrix}
$$

\subsection{多帧坐标系变换结合}
在实验中发现，由相机图像求得的三维特征点比较稳定，而由于激光雷达本身存在传感器误差，其通过直线拟合求交点得到的三维角点不够稳定，在相机与激光雷达位置均固定的情况下，每次测得的激光雷达测得的三维特征角点在会有一个较小的位移，而这样的位移会对用Kabsch算法得到的解产生较大的误差。

为了减小因激光雷达传感器误差而造成的三维特征角点不准确的问题，本文在相机与激光雷达位置固定的情况下，针对多帧图像与点云进行了匹配运算，对$N$次结果进行求取平均值。对平移量的平均值求取公式为
$$\overline{t}=\frac{1}{N}\sum_{i=1}^N{{tvec}_i}$$
而对于旋转量的求取平均值，先将上文求得的旋转转为四元数${rvec}_i$形式，再对四元数求取平均值。
$$r=\frac{1}{N}\sum_{i=1}^N{{rvec}_i}$$
$$\overline{r}=\frac{r}{\|r\|}$$

通过对多帧激光雷达点云与相机进行三维点匹配得到的欧式变换求取平均值，能够有效的抑制因激光雷达的传感器误差而造成的标定误差。

\section{本章小结}

本章介绍了什么是激光雷达点云注册与运动畸变，并且提出了插值矫正运动畸变的方法：在对点云进行多帧融合时，利用点云传输的特性，将点云在时间上为84个Packet单独发布，同时线性插值得到这些Packet的时间戳上的编码器角度值，将这些Packet点云依据编码器的角度注册到参考坐标系中，并且将所有的Packet点云进行叠加注册后发布为新的点云。由于对每帧点云多进行了84次旋转角度的插值，从点云图案上看，本文提到的方法极大地改善了运动畸变对点云注册的影响，完成了矫正运动畸变的目的。同时，本章还介绍了一种利用特制的标定板在相机与激光雷达坐标系中寻找三维特征匹配点的方法来进行相机的标定，并详细介绍了如何利用三维匹配点来计算出两个点集所在的坐标系之间的欧式变换（Kabsch算法）。在后续的章节，本文将利用相机与激光雷达标定出来的$[R|t]$矩阵，对激光雷达与相机图像的数据进行融合处理，借以进行三维障碍物的分割与分类。