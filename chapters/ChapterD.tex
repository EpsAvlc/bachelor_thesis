% !Mode:: "TeX:UTF-8"

\chapter{基于视觉与三维点云融合的三维障碍物检测方法}

随着深度学习领域内的卷积神经网络在目标检测任务中大放异彩，基于视觉的目标检测的深度学习算法大行其道。在著名的大规模目标检测挑战赛ILSVRC\citeup{Li2010lsvrc} 中，基于深度学习的目标检测算法连续六年（2012-2017）取得了优越的表现。2017年，ILSVRC的夺冠深度学习网络SENet在目标检测问题上的错误率仅为$2.251 \%$，亦同时宣告了基于图像的目标检测任务基本被攻克。

然而，基于视觉的目标检测无法得到物体的三维位置信息，并且受光照影响严重。为了解决这些问题，本章后续部分将提出一种激光雷达与相机的多模态传感器融合技术，其能够在基于视觉的目标检测算法检测到目标时，能够根据激光雷达的点云得到障碍物的三维位置信息，同时根据激光雷达的点云信息反馈于目标检测任务的识别上，提升视觉在光照条件不够良好的情况下的检测准确率。

\section{YOLO-一种实时目标检测网络}

在介绍相机图像与激光雷达点云的融合之前，本文将先介绍本文使用的视觉目标检测算法。本文使用YOLO(You Only Look Once)\citeup{redmon2016you}算法作为视觉图像上的目标检测算法。

\pic[htbp]{YOLO-一种实时目标检测网络}{width=0.6\textwidth}{yolo}

早期的目标检测算法通过提取图像的一些特征（例如Haar、SIFT、HOG等），运用DPM（Deformable Parts Model）模型，并且通过滑动窗口来预测具有较高得分的区域的策略来进行目标检测。这种传统的方法不仅相当耗时，而且检测准确率也不是很高。

随后出现了基于object proposal策略的方法，相比于滑动窗口这种类似于穷举的方法，该方法大大减少了运算量，同时定位精度也得到了很大的提高。结合13年兴起的卷积神经网络后，Object detection的性能得到了质的飞跃。

然而，诸如R-CNN、Faster R-CNN这样的网络，因为候选区域较多、网络运算量较大，因而很难在GPU性能不够强劲的移动机器人场景中做到实时检测。而本文采用的YOLO网络将目标检测问题转化为一个回归问题。给定图像$I$，YOLO 网络直接在图像的多个位置上回归出识别目标的bounding box以及其类别。

YOLO没有选择滑动窗口或者提取proposal的策略来训练网络，而是直接将整张图作为网络的输入，既极大地提升了运算速度，亦很好的区分了图像的前景与背景区域，而使用proposal策略的Fast R-CNN则经常将背景区域误识别为目标区域。

\pic[htbp]{YOLO网络结构}{width=1\textwidth}{yolo_net}

图\ref{yolo_net}为YOLO的网络结构，从图中可以看出，该目标检测网络拥有24层卷积层，随后用两层全连接层对结果进行回归输出。

由于其简介的网络结构设计，使得其在实时性能上表现卓越。YOLO能够在每秒推算45帧的情况下仍能够保证和Faster R-CNN同样的准确率。基于其良好的实时性与较为优秀的目标检测准确率，本文将使用YOLO作为视觉与三维点云融合的目标检测基准方法，并利用激光雷达的点云信息为其检测结果提供三维位置信息并提高准确率。

\section{基于YOLO的视觉、三维点云结合的三维障碍物检测}
本章所述的传感器设置如图----所示。其中激光雷达坐标系到相机坐标系的刚体变换已由第二章介绍的标定方法得到。在介绍如何将激光雷达点云投影到相机图像上之前，本文将先介绍相机的成像原理，这是点云投影的理论基础。

\subsection{相机成像原理}

所谓的相机成像，就是相机将三维空间中的坐标映射到二维图像平面的过程。这一映射可以有许多数学模型去解释，最简单也最为常用的就是针孔成像模型，如图所示。

\subsection{激光雷达点云的投影}

\subsection{点云前景与背景的分割}

\subsection{目标三维坐标的计算}

\subsection{YOLO目标检测结果的优化}

\pic[htbp]{enhanced YOLO}{width=1\textwidth}{enhanced_yolo}



\section{本章小结}